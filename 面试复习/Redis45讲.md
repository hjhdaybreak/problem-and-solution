# 基本架构：一个键值数据库包含什么？

```java
一个键值数据库包括了访问框架、索引模块、操作模块和存储模块四部分
```

# 数据结构：快速的Redis有哪些慢操作？

```c
为什么快
1.内存数据库 2.数据结构

底层数据结构一共有 6 种
简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组

键和值用什么结构组织?     
一个哈希表 —— 全局哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。哈希桶中的 entry 元素中保存了*key和*value指针，分别指向了实际的键和值。
    
为什么哈希表操作变慢了？
hash冲突导致拉链过长,效率降低,会进行rehash。rehash一次性把哈希表中的数据都迁移完,会造成 Redis 线程阻塞,无法服务其他请求,所以用渐进式rehash。


集合底层数据结构
整数数组和双向链表, 它们的操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度基本是 O(N)
压缩列表 头尾O(1) 其余O(n) 
跳表 增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位 O(logN)


不同操作的复杂度
"四句口诀" 
1.单元素操作是基础；HGET、HSET 和 HDEL SADD、SREM、SRANDMEMBER O(1)                                       HMGET 和 HMSET,  Set 类型的 SADD O(1~n)
2.范围操作非常耗时；HGETALL,SMEMBERS,LRANGE,ZRANGE O(n) 
  HSCAN,SSCAN 和 ZSCAN 渐进式遍历避免一次性返回所有元素
3.统计操作通常高效；LLEN 和 SCARD O(1) 
4.例外情况只有几个。压缩列表和双向链表都会记录表头和表尾的偏移量 LPOP、RPOP、LPUSH、RPUSH O(1)
```

![img](C:\Users\19235\Desktop\eQvN86R7XDfEJI2.jpg)

![img](G:\markdown图片\fb7e3612ddee8a0ea49b7c40673a0cf0.jpg)

## 课后问题

```java
整数数组和压缩列表在查找时间复杂度方面并没有很大的优势,那为什么 Redis 还会把它们作为底层数据结构呢？
1.内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。
2.数组对CPU高速缓存支持更友好,数组是连续的,所以数组全部或者部分元素被连续存在CPU缓存里面。
```

# 高性能IO模型：为什么单线程Redis能那么快？

```c
Redis 的网络 IO 和键值对读写是由一个线程来完成的。
持久化、异步删除、集群数据同步是由其他的线程完成的。
    
    
Redis 为什么用单线程？为什么不用多线程 ?
多个线程同时访问共享资源,为了保证正确性,就需要额外的机制来保证例如引入同步原语从而导致额外的开销。
    
单线程 Redis 快的原因
1.内存数据库+高效的数据结构, 例如哈希表和跳表
2.基Linux 中的 IO 多路复用机制的高性能 I/O 模型
阻塞IO  accept 等连接、recv 等数据是阻塞操作。可以通过设置非阻塞+I/O多路复用。
{ select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下,该机制允许内核中,同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达,就会交给 Redis 线程处理,这就实现了一个 Redis 线程处理多个 IO 流的效果。Redis 可以同时和多个客户端连接并处理请求,从而提升并发性。
}

连接请求和读数据请求 这两个请求分别对应 Accept 事件和 Read 事件,Redis 分别对这两个事件注册 accept 和 get 回调函数。当 Linux 内核监听到有连接请求或读数据请求时，就会触发 Accept 事件和 Read 事件,此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理。 
```

## 课后问题

```java
在"Redis" 基本 IO 模型”图中，你觉得还有哪些潜在的性能瓶颈吗？
1.使用复杂度过高的命令
2.大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；
3.任意一个请求在server中一旦发生耗时，都会影响整个server的性能
```

# AOF日志：宕机了，Redis如何避免数据丢失？

```java
AOF是写后日志
好处
1.可以避免出现记录错误命令的情况,不会阻塞当前的写操作。
两个潜在的风险
1.写AOF日志也是在主线程中执行的,可能阻塞后续操作
2.写完内存宕机没写AOF,如果Redis当数据库,导致恢复的时候数据丢失。
 
三种写回策略
Always, 同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
Everysec, 每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘;
No, 操作系统控制的写回：每个写命令执行完,只是先把日志写到 AOF 文件的内存缓冲区,由操作系统决定何时将缓冲区内容写回磁盘。

AOF重写
为什么需要重写? 1.文件系统本身对文件大小有限制;2.如果文件太大，之后再往里面追加命令记录的话，效率也会变低 3. 如果发生宕机,用AOF恢复过程慢。

重写机制
重写过程是由fork的后台子进程 bgrewriteaof 来完成的。 使用了写时复制。如果写AOF某个键值对时候父进程没对其执行写操作,那就直接写入AOF文件,如果同时子进程写AOF父进程对其写操作,就会copy一个副本,主线程操作副本,子进程将原键值对写入。
 
AOF重写的过程总结为"一个拷贝,两处日志"。
1.指正在使用的 AOF 日志  2.AOF 重写日志  
```

## 课后问题

```java
AOF 日志重写的时候, 是由 bgrewriteaof 子进程来完成的,不用主线程参与,我们今天说的非阻塞也是指子进程的执行不阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？
1. fork子进程，fork这个瞬间会阻塞主线程的    
    
AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢?
1.避免进程竞争 2.AOF文件被污染没法用来恢复
```

# 内存快照：宕机后，Redis如何实现快速恢复？

```java
内存快照：把某一时刻的状态以文件的形式写到磁盘上,也就是快照。

Redis生成RDB的两种方式 
save：在主线程中执行,会导致阻塞;
bgsave：创建一个子进程，专门用于写入 RDB 文件,避免了主线程的阻塞(默认)。使用写时复制,在执行快照的同时，正常处理写操作。    
    
1.一次全量快照
  
2.增量快照 
       
3.混合使用 AOF 日志和内存快照   
内存快照以一定的频率执行,在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。
下一次做做全量快照时，就可以清空 AOF 日志。
    
  
 
数据不能丢失时, 内存快照和 AOF 的混合使用是一个很好的选择；
如果允许分钟级别的数据丢失,丢失数据不敏感,可以只使用 RDB；
如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。
```

## 课后问题

```java
我曾碰到过这么一个场景：我们使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB，我们使用了 RDB 做持久化保证。当时 Redis 的运行负载以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。你觉得，在这个场景下，用 RDB 做持久化有什么风险吗？你能帮着一起分析分析吗？
    
内存资源风险：Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。
```

#  数据同步：主从库如何实现数据一致？

```java
只使用一个实例宕机了,它在恢复期间,是无法服务新来的数据存取请求的。
   
Redis 高可靠性 一是数据尽量少丢失，二是服务尽量少中断。 
AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。
    

Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。
读操作：主库、从库都可以接收；
写操作：首先到主库执行，然后，主库将写操作同步给从库。

    
    
**主从同步原理**  
三种模式 
 
1.全量复制 
    
2.基于长连接的命令传播

3.增量复制
主从库间网络断开
Redis 2.8 之前库就会和主库重新进行一次全量复制
Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。
缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。
repl_backlog_size = 缓冲空间大小 * 2 
    
主——从——从    
从库比较多，都和主库复制，fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。
```

## 课后问题

```java
主从库间的数据复制同步使用的是 RDB 文件，前面我们学习过，AOF 记录的操作命令更全，相比于 RDB 丢失的数据更少。那么,为什么主从库间的复制不使用 AOF 呢 ?
    
RDB文件内容是经过压缩的二进制数据,文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大。
    
假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。
```

# 哨兵机制：主库挂了，如何不间断服务？

```java
1.主库真的挂了吗？ 2.该选择哪个从库作为主库？ 3.怎么把新主库的相关信息通知给从库和客户端呢？
Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题。
    
哨兵机制的基本流程 监控、选主（选择主库）和通知。
    
监控任务中，哨兵需要判断主库是否处于下线状态    
主观下线：哨兵进程会周期性使用 PING 命令检测它自己和主、从库的网络连接情况,如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为"主观下线" 。 
为了避免误判,通常会采用多实例组成的集群模式进行部署，组成哨兵集群，只有大多数的哨兵实例，都判断主库已经"主观下线"了，主库才会被标记为 "客观下线"。N 个哨兵实例时,要有 N/2 + 1判断主库为 "主观下线"。
    
    
如何选定新主库
检查从库的当前在线状态,过滤不在线,并判断在线从库的网络连接状态。
使用配置项 down-after-milliseconds * 10  down-after-milliseconds(主从库断连的最大连接超时时间)超过十次,就排除它。  进行从库优先级、从库复制进度以及从库 ID 号三轮筛选(不一定三轮,选出就停止)。选为新主库
    
    
Redis 的哨兵机制自动完成了三大功能，从而实现了主从库的自动切换，可以降低 Redis 集群的运维开销
监控主库运行状态，并判断主库是否客观下线；
在主库客观下线后，选取新主库；
选出新主库后，通知从库和客户端。
```

## 课后问题

```java
主从库切换是需要一定时间的。所以，请你考虑下，在这个切换过程中，客户端能否正常地进行请求操作呢？如果想要应用程序不感知服务的中断，还需要哨兵或需要客户端再做些什么吗 ? 
如果客户端使用了读写分离，那么读请求可以在从库上正常执行，不会受到影响,在这期间写请求会失败。
客户端只能把写失败的请求先缓存起来或写入消息队列中间件中,等哨兵切换完主从后，再把这些写请求发给新的主库。
```

# 哨兵集群：哨兵挂了，主从库还能切换吗？

```java
一旦多个实例组成了哨兵集群，即使有哨兵实例出现故障挂掉了，其他哨兵还能继续协作完成主从库切换的工作，包括判定主库是不是处于下线状态，选择新主库，以及通知从库和客户端。
  

配置集群：sentinel monitor <master-name> <ip> <redis-port> <quorum>  哨兵与主库建立连接
    
哨兵集群的组成和运行机制 
基于pub/sub 机制，也就是发布 / 订阅机制   主库提供pub/sub 机制, 哨兵通过在主库上发布自己连接信息,并订阅消息,获取其他哨兵发布的连接信息。Redis通过不同的频道,区分不同应用的消息,只有订阅了同一个频道的应用，才能进行信息交换。哨兵使用的__sentinel__:hello频道,获取其他哨兵的地址,互相建立网络连接,进行通信。

哨兵建立与从库的连接
哨兵向主库发送 INFO 命令,会把从库列表返回给哨兵,哨兵就可以与每个从库建立连接。
  

通过pub/sub 机制,完成哨兵和客户端间的信息同步。
哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息,哨兵提供多个频道,不同频道包含了主从库切换过程中的不同关键事件。
客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取主从库切换过程中的不同关键事件。

选主
选哨兵执行主从切换 
```

## 课后问题

```java
假设有一个 Redis 集群，是“一主四从”，同时配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？此外，哨兵实例是不是越多越好呢，如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处呢？
    
达得到quorum,能判客观下线, 但是不能选主,选主要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。
    
哨兵实例越多，通信的次数也就越多，而且部署多个哨兵时，会分布在不同机器上，节点越多带来的机器故障风险也会越大，这些问题都会影响到哨兵的通信和选举，出问题时也就意味着选举时间会变长，切换主从的时间变久。
    
调大down-after-milliseconds值，对减少误判是不是有好处？
是有好处的，适当调大down-after-milliseconds值，当哨兵与主库之间网络存在短时波动时，可以降低误判的概率。但会带来主从切换的时间会变长,对业务的影响时间越久。
```

# 切(分)片集群：数据增多了，是该加内存还是加实例？

```c++
info stats 查看， 里面有一个 latest_fork_usec 表示最近一次 fork 的耗时 发现很长

RDB 进行持久化时Redis 会 fork 子进程来完成,fork 在执行时会阻塞主线程,数据量越大,阻塞时间越长,导致 Redis 响应变慢 
   
 
纵向扩展（scale up）和横向扩展（scale out）
纵向扩展 加内存,加容量。实施起来简单 适用于不要求持久化保存 Redis数据。但当数据量大生成RDB成本高,fork阻塞主线程,成本逐渐增高。
横向扩展 搭建多个实例,百万、千万级别的用户规模时。

    
数据切片后,在多个实例之间如何分布？
数据和实例之间如何对应 ? 
Redis Cluster用于实现切片集群,该方案中就规定了数据和实例的对应规则。
采用哈希槽来处理数据和实例之间的映射关系,有16384个槽, key按照CRC16 算法计算一个 16 bit 的值;然后,再用这个 16bit 值对 16384 取模,得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。N 个实例,每个实例上的槽个数为 16384/N 个。

  
创建集群的两种方式
1.cluster create创建集群,Redis 会自动把Hash Slot 平均分布在集群实例。
2.cluster meet 命令手动建立实例间的连接,cluster addslots指定实例的哈希槽数量
redis-cli -h 172.16.19.3 –p 6379 cluster addslots 0,1  必须全分完集群才能工作

 
客户端怎么确定想要访问的数据在哪个实例上？    
集群刚创建,每个实例只知道自己被分配了哪些哈希槽,客户端为什么可以在访问任何一个实例时,都能获得所有的哈希槽信呢?
Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例,来完成哈希槽分配信息的扩散。客户端收到哈希槽信息后,会把哈希槽信息缓存在本地。当客户端请求键值对时,会先计算键所对应的哈希槽,然后就可以给相应的实例发送请求了。 

  
实例和哈希槽的对应关系变化    
1在集群中，实例有新增或删除，Redis 需要重新分配哈希槽;
2为了负载均衡,Redis 需要把哈希槽在所有实例上重新分布一遍。    
对客户端是无感的,Redic Cluster提供了重定向功能,当客户端发请求给一个实例,实例上没有这个键值对应的哈希槽,实力会给客户端返回MOVED命令响应。客户端就会再次向相应实例发送请求,同时更新本地缓存。
    
正在迁移
客户端会受到ASK,返回键值所在实例,可能还在本地缓存的实例,也可能已经迁移了。客户端向对应实例发送ASKING,让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送命令。 ASK并不会更新本地缓存。下次还是会发请求给原来的实例,直到迁移完成,请求返回MOVED。    
```

## 课后问题

```java
给你提一个小问题：Redis Cluster 方案通过哈希槽的方式把键值对分配到不同的实例上，这个过程需要对键值对的 key 做 CRC 计算，然后再和哈希槽做映射，这样做有什么好处吗？如果用一个表直接把键值对和实例的对应关系记录下来（例如键值对 1 在实例 2 上，键值对 2 在实例 1 上），这样就不用计算 key 和哈希槽的对应关系了，只用查表就行了，Redis 为什么不这么做呢？
   
1.直接记录每个key对应的实例映射关系,key 非常多,这个映射表会非常庞大,占用大量内存,维护成本高。
2.扩容负载均衡迁移修改映射关系成本高。
```

# 分割线

# 数据结构

#  "万金油”的String"，为什么不好用了？

```c++
String保存 64 位有符号整数 会将它保存为8字节的Long类型整数 int编码
String保存字符串 用简单动态字符串(SDS)

String 会使用额外的内存空间来保存元数据(RedisObject 结构<元数据(一次访问的时间、被引用的次数),指针 >、SDS 结构、dictEntry(哈希桶)结构)

RedisObject 包含了 8 字节的元数据和一个 8 字节指针    
1. Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据
2. 字符串数据,并且字符串小于等于 44 字节时 RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域 embstr 编码    
3. > 44 字节时，SDS 的数据量就开始变多了, Redis 就不再把 SDS 和 RedisObject 布局在一起了,而是会给 SDS 分配独立的空间,并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式。
    
用什么数据结构可以节省内存
压缩列表 (ziplist)
如何用集合类型保存单值的键值对？
可以采用基于 Hash 类型的二级编码方法。
把一个单值的数据拆分成两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value  
Hash 类型 底层使用ziplist key相同下,新增加一个value,只会新增加一个entry。
    
    
hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。超过转哈希表
hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。超过转哈希表
```

## 课后问题

```java
按照惯例，给你提个小问题：除了 String 类型和 Hash 类型，你觉得，还有其他合适的类型可以应用在这节课所说的保存图片的例子吗 ?
```

# 有一亿个keys要统计，应该用哪种集合？

```java
Redis 集合类型的特点就是一个键对应一系列的数据
    
集合类型常见的四种统计模式   

1.聚合统计(交差并)  对多个集合进行聚合计算时，Set 类型合适
    
App 每天的新增用户数(差集)和第二天的留存用户数(交集) 总人数(并集)Set
               des     组成1       组成2
SUNIONSTORE  user:id  user:id  user:id:20200803 把user:id和user:id:20200803装到des中 并集
SDIFFSTORE  差集
SINTERSTORE 交集
S UNION STORE O(N)结果集中的元素数量

聚合计算,数据量大 复杂度高,可以从主从集群中选择一个从库,让它专门负责聚合计算,或者把数据读取到客户端在客户端完成。规避阻塞主库实例和其他从库实例。


2. 排序统计 推荐用Sorted Set
List 和 Sorted Set 就属于有序集合
List在分页统计时,下标范围查询的,新插入数据会导致相对位置改变,导致数据重复展示
Sorted Set 按评论时间设置权重,越新的评论权重越大。ZRANGEBYSCORE ZRANGEBYSCORE comments N-9 N 查10条

    
3.二值状态统计  0 或 1  比如统计一个月签到 Bitmap 
Bitmap 用 String类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型底层是一个字节数组
GETBIT/SETBIT  BITCOUNT   setbit key offset value
支持按位置 与、异或、或   

    
4.基数统计  HyperLogLog节省内存,但不能精确统计 需要准确还是 Set 或 Hash但是耗费内存
网页UV(用户访问) 
Set类型默认支持去重   Hash HSET 同一个key也只保存一次 
PFADD key value1 value2 ...  PFCOUNT 标准误算率是 0.81%   概率算法
```

![img](G:\markdown图片\c0bb35d0d91a62ef4ca1bd939a9b136e.jpg)

# GEO是什么?还可以定义新的数据类型吗？

##### GEO  

```java
位置信息服务（Location-Based Service，LBS）的应用 
key（例如车 ID）对应一个 value（一组经纬度）    
使用Hash 类型可以保存信息,但是不是有序的,不能进行范围查询。    
使用Sorted Set类型可以根据元素的权重分数排序，支持范围查询。    

Sorted Set 权重是一个浮点数 经纬度包含的是经度和纬度两个值,是没法直接保存为一个浮点数的。就用上GEO 类型中的 GeoHash 编码。
GEO 类型的底层数据结构就是用 Sorted Set 来实现的
GeoHash 的编码原理("二分区间，区间编码")

经[-180,180](横) 纬(竖)[-90，90]
先对经度和纬度分别编码,然后再把经纬度各自的编码组合成一个最终编码规则是:最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值，其中，偶数位从 0 开始，奇数位从 1 开始。  (偶经 奇维 从左往右)

有的编码值虽然在大小上接近,但实际对应的方格却距离比较远 
解决：同时查询给定经纬度所在的方格周围的 4 个或 8 个方格。
    
    
**GEO 类型是把经纬度所在的区间编码作为 Sorted Set 中元素的权重分数,把和经纬度相关的车辆 ID 作为 Sorted Set 中元素本身的值保存下来

    
GEOADD添加
GEOADD cars:locations 116.034579 39.030452 33(car Id)   
GEORADIUS获取  
GEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10
```

##### 定义新的数据类型 

![image-20210601220539598](C:\Users\19235\AppData\Roaming\Typora\typora-user-images\image-20210601220539598.png)

```java
Sorted Set + GeoHash 编码实现 GEO   基于 String + 位操作实现 Bitmap
也可以自己实现
基于原有数据类型+新的编码  基于原有数据类型+新的操作
1.定义新数据类型的底层结构   2.RedisObject 的 type 属性中，增加这个新类型的定义 
3.开发新类型的创建和释放函数 4.开发新类型的命令操作
```

# 如何在Redis中保存时间序列数据？

```java
物联网场景中统计设备状态指标值


时间序列数据的读写特点
1.要求写入快 String Hash Sring不适合,因为记录记录小数据时,元数据占用空间大。
2.查询模式多(单点查询、范围查询和聚合计算)   Hash 和 Sorted Set,RedisTimeSeries两种方案
    
Hash 和 Sorted Set组合起来
用 Hash 类型来实现单键的查询很简单 但是它并不支持对数据进行范围查询。时间插入有序,Hash无序。
通过事务 MUTI 与 EXEC 同时插入Hash Sorted Set中,Sorted Set支持范围查询,需要做聚合计算时为了避免阻塞实例,先把数据返回给客户端然后再做聚合计算,但是大量数据在 Redis 实例和客户端间频繁传输,这会和其他操作命令竞争网络资源，导致其他操作变慢。


RedisTimeSeries 支持直接在 Redis 实例上进行聚合计算。 


解决方法
RedisTimeSeries
在实例上先做单个设备聚合(单个设备最大值),得到聚合后结果再返回到客户端。再做所有设备聚合(所有设备最大值)。
能支持在 Redis 实例上直接进行聚合计算，以及按标签属性过滤查询数据集合，当我们需要频繁进行聚合计算，以及从大量集合中筛选出特定设备或用户的数据集合时,可以使用RedisTimeSeries。
    
RedisTimeSeries 的底层数据结构使用了链表，它的范围查询的复杂度是 O(N),查询只能返回最新的数据,不能像Hash 类型返回任意时刻数据。
    
    
SortSet,Set支持直接在实例上做聚合计算,但是为了避免阻塞实例,应该单独拿个库做聚合计算,或者拉取到客户端。
    
    
如果部署环境中网络带宽高、Redis 实例内存大,可以使用Hash 和 Sorted Set组合起来;如果部署环境中网络、内存资源有限，而且数据量大,聚合计算频繁,需要按数据集合属性查询,可以考虑额时间序列。
```

## 课后问题

```java
我提到，我们可以使用 Sorted Set 保存时间序列数据，把时间戳作为 score，把实际的数据作为 member，你觉得这样保存数据有没有潜在的风险？
如果对某一个对象的时序数据记录很频繁的话，那么这个key很容易变成一个bigkey，在key过期释放内存时可能引发阻塞风险。

把聚合计算也设计为Sorted Set的内在功能吗？
不会。因为聚合计算是CPU密集型任务，Redis在处理请求时是单线程的，也就是它在做聚合计算时无法利用到多核CPU来提升计算速度，如果计算量太大，这也会导致Redis的响应延迟变长，影响Redis的性能。
```



# 消息队列的考验：Redis有哪些解决方案？

```java
消息队列的消息存取需求
需求一：消息保序
需求二：重复消息处理     有时会因为网络堵塞而出现消息重传的情况。此时，消费者可能会收到多条重复的消息。
需求三：消息可靠性保证   故障或宕机导致消息没处理完。
Redis 的 List 和 Streams 两种数据类型，就可以满足消息队列的这三个需求。

List 本身就是按先进先出的顺序对数据进行存取的能满足消息保序的需求了。
消息保顺序: BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据
重复消息处理: 通过全局唯一ID 实现幂等性，幂等性就是指，对于同一条消息，消费者收到一次的处理结果和收到多次的处理结果是一致的。
消息可靠性保证: BRPOPLPUSH 命令, 从一个 List 中读取消息,同时,Redis会把这个消息再插入到另一个 List（可以叫作备份 List）留存
List作为消息队列缺点： 生产者消息发送很快，消费者处理的慢,导致消息堆积,内存占用大。

-------------------------------------------------------------------------------------
Redis 从 5.0 Streams 数据类型 相比List支持消费组形式的消息读取 专门为消息队列设计的数据类型

Redis 是轻量级的消息队列,适合处理消息量不大。
```

![img](https://i.loli.net/2021/08/10/wDqbBCo1A2yWFvQ.jpg)



# 分割线

# 影响Redis 性能的 5 大方面的潜在因素

1. Redis 内部的阻塞式操作；
2. CPU 核和 NUMA 架构的影响；
3. Redis 关键系统配置；
4. Redis 内存碎片；
5. Redis 缓冲区。

# 异步机制：如何避免单线程模型的阻塞？

针对主线程的

```java
Redis 的阻塞点 如图
1.和客户端交互时的阻塞点
   网络使用IO多路复用不会导致阻塞
  (1) 集合全量查询(HGETALL,SMEMBERS) 和 聚合操作 
  (2)删除bigKey在应用程序释放内存时,操作系统需要把释放掉的内存块插入一个空闲内存块的链表,以便后续进行管理和再分              配。释放了大量内存，空闲内存块链表操作时间就会增加，相应地就会造成 Redis 主线程的阻塞。
  (3)清空数据库 涉及到删除和释放所有的键值对
2.和磁盘交互时的阻塞点
  子进程的方式生成 RDB 快照文件，以及执行 AOF 日志重写操作,不是阻塞主要因素。
  (4)AOF 日志同步步写回,写磁盘,会阻塞。
3.主从节点交互时的阻塞点
  接收RDB快照要FLUSHDB(3)
  (5)加载 RDB 文件    把主库实例的数据量大小控制在 2~ 4 GB，以免主从复制时,从库因加载大的 RDB 文件而阻塞。
4.切片集群实例交互时的阻塞点
  负载均衡或者有实例增删时,数据会在不同的实例间进行迁移(渐进式),如果有bigKey就会造成主线程的阻塞。
    
    
应对阻塞 
启动一些子线程,然后把一些(非关键路径上的任务)任务交给这些子线程,让它们在后台完成。
    关键路径 1.读 集合全量查询和聚合操作
            2.从库加载 RDB 文件
    bigkey 删除、清空数据库、AOF 日志同步写不属于关键路径操作  可用子线程完成。

    
异步的子线程机制
  Redis 在运行时会创建三个子线程，主线程会通过一个任务队列和三个子线程进行交互。  pthread_create 函数创建 3 个子线程,子线程会根据任务的具体类型,来执行相应的异步操作。
    
4.0之后 提供了惰性删除
异步的键值对删除和数据库清空操作 Redis 4.0
  键值对删除 集合类型中有大量元素  UNLINK 命令    4.0之前SCAN 命令读取数据,再删除,避免一次性删除大量的 key
  清空数据库 FLUSHDB ASYNC  
    
    
不能用子线程如何应对阻塞
    集合全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算；
    从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB 左右，以保证 RDB 文件能以较快的速度加载。
```

![img](https://i.loli.net/2021/08/10/MxL8sV4cKkmiPfn.jpg)

## 课后问题

```java
Redis 的写操作（例如 SET、HSET、SADD 等）是在关键路径上吗?
    
1.如果客户端不关心返回值，只关心数据是否写入成功，那么SET/HSET/SADD不算关键路径，多次执行这些命令都是幂等的，这种情况下可以放到异步线程中执行。
2.如果客户端依赖操作返回值的不同，进而需要处理不同的业务逻辑，那么HSET和SADD操作算关键路径,而SET操作不算关键路径。因为SET操作返回的结果都是OK,客户端不需要关心结果有什么不同。HSET和SADD,如果field或member不存在时，Redis结果会返回1，否则返回0。
```

# 为什么CPU结构也会影响Redis的性能？



# 波动的响应延迟：如何应对变慢的Redis？（上）

```java
判断Redis是否变慢  
1.redis-cli --latency -h host -p port 查看响应延迟 但不同软硬件性能判断标准不一
(毕竟不同主机软硬件配置不一样)
  
2.基于当前环境下的 Redis 基线性能做判断
基线性能(一个系统在低压力、无干扰下的基本性能,这个性能(基线性能)只由当前的软硬件配置决定) 
./redis-cli --intrinsic(基本)-latency(延迟时间) 120(监控多少秒内) 
响应延迟是基线性能两倍以上,就认为Redis变慢了。 
避免网络影响,应该运行在服务端。
要测网络对Redis性能影响可以用iPerf工具。   
    
影响Redis性能的三大要素 
(一)Redis 自身操作特性的影响 
1.慢查询命令  用其他高效命令代替 聚合计算读取到客户端,再自己处理。
  通过Redis 日志,或者是 latency monitor 工具，查询变慢的请求
2.过期 key 的自动删除机制 (删除是会导致Redis操作阻塞的)
    key 的自动删除机制 默认情况下,Redis 每 100 毫秒会删除一些过期 key
    (1)扫描最多ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP(默认20)个要过期的键,100毫秒执行一次，1秒就是要过期200个key。
    (2)如果超过 25% 的 key 过期了，则重复删除的过程，直到过期 key 的比例降至 25% 以下。
同一秒内有大量的 key 同时过期 会触发(2),可以在过期函数上加一个随机数 
```

## 课后问题

```java
有哪些其他命令可以代替 KEYS 命令，实现同样的功能呢？这些命令的复杂度会导致 Redis 变慢吗 ?
SCAN
```

# 波动的响应延迟：如何应对变慢的Redis？（下）

```java
(二)文件系统对 Redis 性能的影响
AOF  everysec Redis 会使用后台的子线程异步完成 fsync 的操作
     always   策略使用的主线程
  
AOF 重写导致磁盘压力大 会导致fsync阻塞, 当主线程使用后台子线程执行了一次 fsync,需要再次把新接收的操作记录写回磁盘时,主线程发现上一次的 fsync 还没有执行完,那么它就会阻塞。
换机械硬盘

(三)操作系统对 Redis 性能的影响
操作系统SWAP 
Redis 是内存数据库,它本身会导致内存占用很大,如果内存不足就可能触发swap,Redis读取数据,则要从磁盘读入,直接导致了Redis主线程变慢,增加机器的内存或者使用 Redis 集群(分摊每个实例服务的数据量，进而减少每个实例所需的内存量),选用内存大的做主库。
   
内存大页
支持分配很大的内存页
Redis 做持久化保存过程中,主线程仍然能够接收命令,Redis会采用写时复制,会导致拷贝大量的页,导致性能变慢。
```

checkList

```java
1.获取 Redis 实例在当前环境下的基线性能。
2.是否用了慢查询命令？如果是的话，就使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做。
3.是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除。
4.是否存在 bigkey? 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成。
5.Redis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加。当然， 如果既需要高性能又需要高可靠性，最好使用高速固态盘作为 AOF 日志的写入盘。
6.Redis 实例的内存使用是否过大？发生 swap 了吗？如果是的话，就增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况。
7.在 Redis 实例的运行环境中，是否启用了透明大页机制？如果是的话，直接关闭内存大页机制就行了。
8.是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞。
9.是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上。
```

# 删除数据后，为什么内存占用率还是很高？

```react
数据删除后, Redis 释放的内存空间会由内存分配器管理，并不会立即返回给操作系统。所以，操作系统仍然会记录着给 Redis 分配了大量内存。 

Redis 释放的内存空间可能并不是连续的，那么，这些不连续的内存空间很有可能处于一种闲置的状态,虽然有空闲空间，Redis 却无法用来保存数据，不仅会减少 Redis 能够实际保存的数据量,还会降低 Redis 运行机器的成本回报率

内存碎片是如何形成
1.外因：键值对大小不一样和删改操作
2.内因：操作系统的内存分配机制
libc、jemalloc、tcmalloc 分配策略 
内因 按照jemalloc(默认) 2^n 次幂 固定分配,可能用不完。
外因 大小不一的键值对和键值对修改删除导致空间的扩容和释放。

1.判断是否有内存碎片
INFO memory 中 mem_fragmentation_ratio=操作系统分配的内存空间/Redis使用的空间
mem_fragmentation_ratio 1-1.5正常

解决内存碎片的方法
1.重启
2.Redis4.0 提供了碎片清理机制  将不连续的空间清理为连续的
影响：Redis 是单线程,在数据拷贝时,Redis 只能等着,这就导致 Redis 无法及时处理请求，性能就会降低。
可以通过配置,减少对Redis处理请求的影响。
```

# 缓冲区：一个可能引发 "惨案" 的地方

```java
Redis 中的缓冲区的功能主要就是用一块内存空间来暂时存放命令数据,以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题 


缓冲区在Redis中的应用场景
1.暂存客户端发送的命令数据 2.暂存服务器端返回给客户端的数据结果 3.主从节点间进行数据同步时,用来暂存主节点接收的写命令和数据。

客户端输入和输出缓冲区
    
如何应对输入缓冲区溢出? 
发生溢出情况
1.写入了 bigkey,比如一下子写入了多个百万级别的集合类型数据
2.服务器端处理请求的速度过慢，导致客户端输入缓冲区堆积。
CLIENT LIST     qbuf已使用,qbuf-free尚未使用 如果溢出了 Redis 会把客户端连接关闭。

当多个客户端所占内存总量超过maxmemory(4GB),就会触发数据淘汰,降低了业务应用的访问性能。
客户端过多也可能导致OOM,Redis直接嘎嘣。

应对溢出方法
1.避免bigKey 
2.避免Redis主线程阻塞(用异步的删除操作)。 没有办法调整输入缓冲区,都是固定1GB。
--------------------------------------------------- 
如何应对输出缓冲区溢出？
输出缓冲区 16KB固定缓冲空间(OK+出错信息) + 动态增加的缓冲空间(可变的响应结果)

会发生输出缓冲区溢出情况
1.返回bigkey 
2.MONITOR命令输出结果会持续输出监测到的各个命令操作占用输出缓冲区。 
3.缓冲区大小设置得不合理。 client-output-buffer-limit 设置合理的客户端缓冲区大小限制,缓冲区持续写入量限制和持续写入时间限制


不同客户端client-output-buffer-limit的配置
客户端种类
1.常规和 Redis 服务器端进行读写命令交互的普通客户端  阻塞式发送(停等协议)不做限制
2.订阅了 Redis 频道的订阅客户端  不属于阻塞式发送,需要设置限制。
3.主节点上的从节点客户端,用来和从节点进行数据同步

避免输出缓冲区溢出的方法
1避免 bigkey 操作返回大量数据结果;
2避免在线上环境中持续使用 MONITOR 命令。
3.使用 client-output-buffer-limit 针对不同的客户端设置合理的缓冲区大小上限,设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值    
    
   
主从集群中的缓冲区
主从集群中的缓冲区包括复制缓冲区和复制积压缓冲区
 
复制缓冲区(全增量复制) 传输RDB的同时,将接收到的客户端信息保存在复制缓冲区,传输完毕后,再发给从节点执行,保证数据同步。
溢出导致主节点会直接关闭和从节点进行复制操作的连接,导致全量复制失败。

如何避免复制缓冲区溢出 
1.控制主节点保存数据量的大小,2-4GB,让全同步执行的快,避免复制缓冲区积累过多的命令。
2.client-output-buffer-limit 配置项，来设置合理的复制缓冲区大小。
3.主节点上复制缓冲区的内存开销,会是每个从节点客户端输出缓冲区占用内存的总和。控制从节点的数量,来避免主节点中复制缓冲区占用过多内存的问题。
    
    
复制积压缓冲区(增量复制)
是一个环形缓冲区,溢出就相当于覆盖旧命令数据,一旦覆盖就要主从节点全增量复制。
```

## 课后问题

```java
我们提到 Redis 采用了 client-server 架构，服务器端会为每个客户端维护输入、输出缓冲区。那么，应用程序和 Redis 实例交互时，应用程序中使用的客户端需要使用缓冲区吗？如果使用的话，对 Redis 的性能和内存使用会有影响吗?
    
缓冲区其实无处不在,客户端缓冲区、服务端缓冲区、操作系统网络缓冲区等等,凡是进行数据交互的两端,一般都会利用缓冲区来降低两端速度不匹配的影响。 
```

# 旁路缓存：Redis是如何工作的？

```java
本章节就讲Redis用做缓存

缓存的特征 
1.快 
2.容量小
Redis 天然就具有高性能访问和数据淘汰机制,正好符合缓存的这两个特征的要求,所以非常适合用作缓存。

Redis 缓存处理请求的两种情况 1.缓存命中 2.缓存缺失,进行缓存更新(读数据库,写入Redis)。

Redis 缓存时,我们基本有三个操作
1.先读取 Redis
2.发生缓存缺失时,需要从数据库读取数据
3.发生缓存缺失时,还需要更新缓存。
    
    
Redis 作为旁路缓存的使用操作  只有提供Redis接口的程序才能用Redis比如java,C,C++,go,py
当应用程序需要读取数据时，我们需要在代码中显式调用 Redis 的 GET 操作接口，进行查询；
如果缓存缺失了，应用程序需要再和数据库连接，从数据库中读取数据；
当缓存中的数据需要更新时，我们也需要在应用程序中显式地调用 SET 操作接口，把更新的数据写入缓存。


缓存的类型
1.只读缓存  (写请求直接发给数据库,Redis缓存命中则删除,没命中则不管,下次会发生缓存缺失,从数据库中读。)
只读缓存直接在数据库中更新数据的好处是,所有最新的数据都在数据库中,而数据库是提供数据可靠性保障的,这些数据不会有丢失的风险。
2.读写缓存  读写请求都会发给Redis
有同步直写,异步写回两种策略
同步直写: Redis Mysql 两者都写完了才返回,增加了缓存的响应延迟   
异步写回: 等待数据将要被淘汰的时候才会写回,有丢失风险。
   

如果写请求很少,或者是只需要提升读请求的响应速度的话,我们选择只读缓存。
如果需要对写请求进行加速(异步写回),我们选择读写缓存;
```

## 课后问题

```java
我提到了 Redis 只读缓存和使用直写策略的读写缓存，这两种缓存都会把数据同步写到后端数据库中，你觉得，它们有什么区别吗? 
    
使用只读缓存时，是先把修改写到后端数据库中，再把缓存中的数据删除。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。

使用读写缓存时，是同时修改数据库和缓存中的值。
```

# 替换策略：缓存满了怎么办？

```java
为了保证较高的性价比,缓存的空间容量必然要小于后端数据库的数据总量

数据淘汰机制(缓存替换机制)
第一,根据一定的策略,筛选出对应用访问来说“不重要”的数据；
第二,将这些数据从缓存中删除，为新来的数据腾出空间
  
设置多大的缓存容量合适 ?    
长尾效应  重尾效应
长尾效应  20% 数据提供 80% 的访问 
重尾效应  视频网站用户个性化的需求 , 80% 数据反而提供更多的访问
需要结合应用数据实际访问特征和成本开销来综合考虑的
设置Redis缓存大小 CONFIG SET maxmemory 4GB
    
Redis 缓存有哪些淘汰策略
见下截图
noeviction 策略 不淘汰直接返回错误,Redis做缓存的时候不使用该策略。
volatile-random 设置了过期时间的键值对中,进行随机删除
volatile-ttl    设置了过期时间的键值对,根据过期时间的先后进行删除
volatile-lru    使用 LRU 算法筛选设置了过期时间的键值对。
volatile-lfu    使用 LFU 算法选择设置了过期时间的键值对。
allkeys-random  从所有键值对中随机选择并删除数据；   
allkeys-lru     使用 LRU 算法在所有数据中进行筛选。    
allkeys-lfu     使用 LFU 算法在所有数据中进行筛选。    
    
Redis LRU的实现
Redis 并没有为所有的数据维护一个全局的链表,而是通过随机采样方式
Redis 默认会记录每个数据的最近一次访问的时间戳(由键值对数据结构 RedisObject 中的 lru 字段记录)。然后,Redis 在决定淘汰的数据时,第一次会随机选出 N 个数据,把它们作为一个候选集合。接下来,Redis 会比较这 N 个数据的 lru 字段,把 lru 字段值最小的数据从缓存中淘汰出去。
    
CONFIG SET maxmemory-samples 100 设置候选集的个数
    
当需要再次淘汰数据时,Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是:能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。当有新数据进入候选数据集后,如果候选数据集中的数据个数达到了 maxmemory-samples,Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。
    
    
业务数据中有明显的冷热数据区分   allkeys-lru 策略
没有明显的冷热数据区分          allkeys-random 策略
业务中有置顶的需求              volatile-lru 策略{置顶的数据不设置过期时间,而其他数据会在过期时根据 LRU 规则进行筛选。}

如何处理被淘汰的数据?
干净数据直接删除,脏数据写回数据库。  !!!  如果数据被修改了,需要在数据修改时就将它写回数据库。
```

![img](https://static001.geekbang.org/resource/image/04/f6/04bdd13b760016ec3b30f4b02e133df6.jpg)

## 课后问题

```java
Redis在用作缓存时,使用只读缓存或读写缓存的哪种模式 ? 
1、只读缓存模式:每次修改直接写入后端数据库,如果Redis缓存不命中,则什么都不用操作,如果Redis缓存命中,则删除缓存中的数据,待下次读取时从后端数据库中加载最新值到缓存中。
2、读写缓存模式+同步直写策略:由于Redis在淘汰数据时,直接在内部删除键值对,外部无法介入处理脏数据写回数据库，所以使用Redis作读写缓存时,只能采用同步直写策略,修改缓存的同时也要写入到后端数据库中,从而保证修改操作不被丢失。
```



# 缓存异常（上）：如何解决缓存和数据库的数据不一致问题？

```java
缓存异常
1.缓存中的数据和数据库中的不一致  下单异常
2.缓存雪崩
3.缓存击穿
4.缓存穿透

什么是数据的一致性? 
缓存和数据库一致性 
缓存中有数据,那么缓存的数据值需要和数据库中的值相同;缓存中本身没有数据,那么数据库中的值必须是最新值。
除此之外就属于缓存和数据库的数据不一致问题

    
不同缓存读写模式下的缓存不一致情况?

读写缓存 
保证缓存和数据库中的数据一致,就要采用同步直写策略。如果采用异步写回,如果数据还没有写回数据库,缓存就发生了故障,导致出现缓存一致性问题。
    
只读缓存
    

    
出现缓存不一致情况
1.新增数据 不会出现不一致
2.删改数据  如果不能保证删除缓存和数据库操作的原子性就会出现 下图1

    
解决缓存不一致的方法
删除缓存值或更新数据库失败而导致数据不一致,你可以使用重试机制确保删除或更新操作成功。
在删除缓存值、更新数据库的这两步操作中,有其他线程的并发读操作,导致其他线程读取到旧值,应对方案是延迟双删。
```

![img](https://i.loli.net/2021/08/13/azy953YcBbOVpCh.jpg)

![img](https://static001.geekbang.org/resource/image/11/6f/11ae5e620c63de76448bc658fe6a496f.jpg)

# 缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？

```java
缓存雪崩   

监测 Redis 缓存所在机器和数据库所在机器的负载指标 Redis 缓存实例宕机了,而数据库所在机器的负载压力突然增加,发生缓存雪崩。

是指大量的应用请求无法在 Redis 缓存中进行处理,紧接着,应用将大量请求发送到数据库层,导致数据库层的压力激增。
1.某一个时刻,大量数据同时过期,再请求发生缓存缺失,发给数据库  2.Redis实例宕机
解决
   1.1用 EXPIRE 命令给每个数据设置过期时间时,给这些数据的过期时间增加一个较小的随机数 
   1.2服务降级,来应对缓存雪崩 非核心业务 直接返回预定义信息、空值或是错误信息
      核心业务仍允许查询缓存,数据库。
     
   2.1服务熔断,暂停业务应用对缓存系统的接口访问,客户端不会把请求发给Redis实例直接返回,直到其恢复 
   2.2请求限流 请求入口前端控制每秒进入系统的请求数 
   2.3事前预防,高可用集群,Redis 缓存的主节点故障宕机了,从节点还可以切换成为主节点,继续提供缓存服务
   
缓存击穿 (热数据失效)
针对的是热数据的请求,无法在缓存中进行处理,紧接着,访问该数据的大量请求，一下子都发送到了后端数据库
解决 访问特别频繁的热点数据,我们就不设置过期时间了
    
    
缓存穿透 影响最大
缓存穿透是指要访问的数据既不在 Redis 缓存中,也不在数据库中,导致请求在访问缓存时,发生缓存缺失,再去访问数据库时,发现数据库中也没有要访问的数据。
1.业务层误操作 缓存中的数据和数据库中的数据被误删除了
2.恶意攻击：专门访问数据库中没有的数据
解决方法: 1缓存空值或缺省值
        
2 布隆过滤器快速判断数据是否存在,避免从数据库中查询数据是否存在,减轻数据库压力
{		
   想标记某个数据存在时
   布隆过滤器由一个初值都为 0 的 bit 数组和 N 个哈希函数组成
       1.首先,使用 N 个哈希函数,分别计算这个数据的哈希值,得到 N 个哈希值。
       2.然后,我们把这 N 个哈希值对 bit 数组的长度取模，得到每个哈希值在数组中的对应位置。
       3.最后,我们把对应位置的 bit 位设置为 1,这就完成了在布隆过滤器中标记数据的操作。
      查询时: 得到这个数据在 bit 数组中对应的 N 个位置,只要这N个位置一个不为1,就说明查询的数据没有在数       据库中保存
      即使发生缓存穿透了,大量请求只会查询 Redis 和布隆过滤器,而不会积压到数据库,也就不会影响数据库的正常运行。布隆过滤器本身也可用Redis实现。
}

3前端进行请求检测,过滤掉非法请求
    
针对缓存雪崩,合理地设置数据过期时间,以及搭建高可靠缓存集群；
针对缓存击穿,在缓存访问非常频繁的热点数据时,不要设置过期时间；
针对缓存穿透,提前在入口前端实现恶意请求检测，或者规范数据库的数据删除操作,避免误删除。
```

![img](G:\markdown图片\b5bd931239be18bef24b2ef36c70e9e1.jpg)

## 课后问题

```java
服务熔断、服务降级、请求限流的方法来应对。请你思考下，这三个机制可以用来应对缓存穿透问题吗
如果是恶意攻击,可以采取。
如果是误删除,只需要恢复即可。
```

# 缓存被污染了，该怎么办？

```java
缓存污染 访问很少,却一直留在缓存中,占空间。

如何解决缓存污染问题？
1. volatile-random 和  allkeys-random   能力有限    
    
2. 只有在明确知道数据被再次访问的情况下, volatile-ttl 可以有效避免缓存污染  在其他情况下 volatile-random、allkeys-random、volatile-ttl都不能应对缓存污染。

3. LRU 策略在处理扫描式单次查询操作时,无法解决缓存污染,因为数据只被访问一次,lru 字段值都很大,无法应对。

因而 4.0 引入了LFU 
LFU 策略筛选淘汰数据时,首先会根据数据的访问次数进行筛选,把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同,LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。


LFU是在LRU上的改进把lru 字段24bit  前16bit表示数据时间戳,后8bit表示访问次数 先根据次数再根据时间 
但是只能记录8bit 访问255次,所以并未采取访问1加1 而是
   
非线性递增的计数器方法: 用计数器当前的值乘以配置项 lfu_log_factor 再加 1,再取其倒数,得到一个 p 值;然后,把这个 p 值和一个取值范围在 (0,1) 间的随机数 r 值比大小，只有 p 值大于 r 值时,计数器才加 1 。 
在应用 LFU 策略时,一般可以将 lfu_log_factor 取值为 10。

避免短时间大量访问,后不访问 LFU策略使用衰减因子 lfu_decay_time 来控制访问次数的衰减
当前时间和数据最近一次访问时间的差值,并把这个差值换算成以分钟为单位。然后,LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。
  
LRU 策略更加关注数据的时效性,而 LFU 策略更加关注数据的访问频次。 
扫描式查询的应用场景中,LFU 策略就可以很好地应对缓存污染问题了
```

## 课后问题

```java
LFU 策略后，你觉得缓存还会被污染吗 ? 
被污染的概率取决于LFU的配置 
```

# 无锁的原子操作：Redis如何应对并发访问？

```java
什么是并发控制?
并发控制,就是要保证临界区代码的互斥执行。
    
为了保证并发访问的正确性,Redis 提供了两种方法,分别是加锁和原子操作 多客户端需要分布式锁

1 原子操作
1.1 把多个操作在 Redis 中实现成一个操作 —— 单命令操作
INCR/DECR  读取修改写回的原子操作 

1.2 把多个操作写到一个 Lua 脚本中,以原子性方式执行单个 Lua 脚本
不是简单地增减数据,而是有更加复杂的判断逻辑或者是其他操作,Lua 脚本 EVAL 命令来执行脚本   


   
控制一段时间用户的访问次数
用户第一次访问的时候,设置一个过期键,key为用户ip,值为访问次数,每次访问就增加次数,超过限制就报错。  键过期后下次用户访问重新生成键值对。
```

## 课后问题

```java
Redis 在执行 Lua 脚本时，是可以保证原子性的，那么，在我举的 Lua 脚本例子（lua.script）中，你觉得是否需要把读取客户端 ip 的访问次数，也就是 GET(ip)，以及判断访问次数是否超过 20 的判断逻辑，也加到 Lua 脚本中吗？
    
在编写 Lua 脚本时,要避免把不需要做并发控制的操作写入脚本中。
    
1、这2个逻辑都是读操作,不会对资源临界区产生修改,所以不需要做并发控制。

2、减少 lua 脚本中的命令,可以降低Redis执行脚本的时间,避免阻塞Redis。
 
LUA只用包含 第一次访问设置过期时间,后续访问判断是否是第一次,不是就访问次数++;
```



# 如何使用Redis实现分布式锁？

```java
分布式锁是保存在一个共享存储系统中的,可以被多个客户端共享访问和获取。 Redis本身就是共享存储系统
    
分布式锁的两个要求
    1.分布式锁的加锁和释放锁的过程,涉及多个操作。所以,在实现分布式锁时,我们需要保证这些锁操作的原子性;
    2.保证共享存储系统的可靠性,进而保证锁的可靠性。
        
Redis实现分布式锁   
        
基于单个 Redis 节点实现分布式锁 Redis 会把同时收到的请求串行化   使用SETNX 和 DEL 命令组合来实现加锁和释放锁
        
风险与应对 
1.SETNX之后,操作共享数据时发生了异常,结果一直没有执行最后的 DEL 命令释放锁,会导致获取锁的客户端持续持有锁
解决方法:给锁变量设置一个过期时间   SETNX 设置的键值对(也就是锁变量)不存在 先创建键值对,然后设置它的值

2.误释放锁,A 执行了 SETNX 命令加锁后,假设客户端 B 执行了 DEL 命令释放锁,此时,客户端 A 的锁就被误释放了。如果客户端 C 正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。 
解决方法: 锁变量设置一个唯一值,释放锁时候,锁变量的值是和自己的唯一标识相等才会释放
 
加锁  SET key value [EX seconds | PX milliseconds]  [NX] NX表示不存在就创建  EX/PX设置过期时间
解锁LUA脚本    
//释放锁 比较unique_value是否相等，避免误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
解锁  redis-cli  --eval  unlock.script lock_key,unique_value  
 
Redis 实例发生故障宕机了,锁变量没有了,也就无法进行锁操作了
  
    
基于多个 Redis 节点实现高可靠的分布式锁

分布式锁算法 Redlock
客户端和多个独立的 Redis 实例依次请求加锁,如果客户端能够和半数以上的实例成功地完成加锁操作,那么我们就认为,客户端成功地获得分布式锁了,否则加锁失败。
加锁三个过程:   
           1.客户端获取当前时间。
           2. 客户端按顺序依次向 N 个 Redis 实例执行加锁操作。加锁命令:SET lock_key unique_value NX PX                一直到超时都没有成功,则会和下一个实例继续请求加锁 
           3.一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时。
           两个必须满足的条件
               3.1 大于等于 N/2+1 个实例加锁成功
               3.2 客户端获取锁的总耗时没有超过锁的有效时间。
           重新计算锁剩余有效时间如果锁的有效时间已经来不及完成共享数据的操作了,我们可以释放锁,以免出现还没完成数据操作,锁就过期了的情况。
           条件不满足客户端向所有 Redis 节点发起释放锁(执行解锁LUA脚本)的操作。
```

## 课后问题

```java
我们可以使用 SET 命令带上 NX 和 EX/PX 选项进行加锁操作，那么，我想请你再思考一下，我们是否可以用下面的方式来实现加锁操作呢？
    
// 加锁
SETNX lock_key unique_value
EXPIRE lock_key 10S
// 业务逻辑
DO THINGS
    
就是把加锁分成两部,能行吗? 不能！！ 必须要保证原子性

1、SETNX 执行成功,执行 EXPIRE 时由于网络问题设置过期失败

2、SETNX 执行成功,此时 Redis 实例宕机,EXPIRE 没有机会执行

3、SETNX 执行成功,客户端异常崩溃,EXPIRE 没有机会执行
```

# 事务机制：Redis能实现ACID属性吗？

```java
原子性 (Atomicity)、一致性(Consistency)、隔离性(Isolation) 和持久性 (Durability)

Redis 如何实现事务 ? 
MULTI开启一个事务,命令入队,EXEC执行队列中的命令。 DISCARD主动放弃事务,清空任务队列。

Redis 的事务机制能保证哪些属性 ? 
    
原子性 
1.命令入队时就报错,执行EXEC后拒绝执行所有提交的命令操作放弃执行事务,保证原子性;
2.命令入队时没报错,实际执行时报错,但会把正确的命令执行完,不保证原子性;
3.EXEC 命令执行时实例故障,如果开启了 AOF 日志,可以保证原子性。使用 redis-check-aof工具 去除AOF中未完成的事务操作,使用AOF恢复实例后,可以保证原子性。


一致性
都可以保证
1.命令入队时就报错,事务本身就会被放弃执行
2.命令入队时没报错,实际执行时报错,正确的命令可以正常执行。
3.EXEC 命令执行时实例发生故障,没有开启RDB或AOF,数据就没有了,能保障。开启了RDB或AOF,RDB快照不会在事务执行时执行,使用 RDB 快照进行恢复,数据库里的数据也是一致的。开启AOF可以利用redis-check-aof 清除事务中已经完成的操作,也能保障。
    
    
隔离性 WATCH机制 
1.MULTI 命令前有 WATCH命令,就能保证隔离性。
EXEC时,WATCH 机制会先检查监控的键是否被其它客户端修改了,如果修改了,就放弃事务执行,避免事务的隔离性被破坏。
2.并发操作在 EXEC 命令之后被服务器端接收并执行。EXEC会保证先把命令队列的命令执行完毕,能保障隔离性。
        
持久性 
Redis 采用什么持久化模式，事务的持久性属性是得不到保证的。
1.没有RDB或AOF
2.执行事务后,在下一次RDB快照之前宕机了
3.AOF三种配置都存在数据丢失的可能。
    
因为是内存数据库 持久性不是重点
```

![img](https://i.loli.net/2021/08/15/AuMJEKBk5F6Xpdi.jpg)

## 课后问题

```java
如果 Redis 实例发生故障,而 Redis 使用了 RDB 机制,那么,事务的原子性还能得到保证吗 ? 

可以 
如果一个事务只执行了一半,然后 Redis 实例故障宕机了,由于 RDB 不会在事务执行时执行,所以 RDB 文件中不会记录只执行了一部分的结果数据。之后用 RDB 恢复实例数据,恢复的还是事务之前的数据。但 RDB 本身是快照持久化,所以会存在数据丢失,丢失的是距离上一次 RDB 之间的所有更改操作。
```



# Redis主从同步与故障切换，有哪些坑？

```java
分别是主从数据不一致、读到过期数据,以及配置项设置得不合理从而导致服务挂掉。

1主从数据不一致
主从库间的命令复制是异步 主从库命令传播阶段,主库收到新的写命令后,会发送给从库
主库在本地执行完毕就会返回,从库还没执行传过来的数据
原因是: 1.主从库间的网络   2.从库收到并执行主库传过来的命令,但正在执行高复杂度的命令,之后才会执行传播过来的命令。

解决
1.保证主从库间的网络连接状况良好,同一机房
2.监控主从库间的复制进度 INFO Replication 查master_repl_offset 减去 slave_repl_offset 大于某个阈值,就在客户端移除与这个从库的连接。
    
2 读取过期数据

2.1  惰性删除,对于主库,数据过期了下次访问会删除。对于从库,Redis<3.2会直接返回,>3.2会返回null,但不会删除。
     
2.2  定期删除策略 Redis 每隔一段时间(默认 100ms),就会随机选出一定数量的数据,检查它们是否过期,并把其中过期的数据删除,这样就可以及时释放一些内存。Redis 为了避免过多删除操作对性能产生影响，每次随机检查数据的数量并不多。仍然可能读取到过期没删除的。
     
2.3 EXPIRE 和 PEXPIRE 过期时间是从命令执行开始为标准 主从库命令传播需要时间
使用EXPIREAT / PEXPIREAT 将过期时间设置为具体的过期时间点 
    
3.不合理配置项导致的服务挂掉 
protected-mode yes 哨兵实例除了本地其他服务器没法访问 会导致Sentienel之间无法通信,主库故障,无法判断主库下线,无法进行主从切换。
protected-mode no bind 192.168.10.3 192.168.10.4 192.168.10.5 这样既保证安全保障,哨兵集群也能相互通信
    
集群挂掉   
主从集群主实例故障主从切换由于网络原因,时间超过cluster-node-timeout,会被判断异常,当半数以上主从切换时候,时间都超过cluster-node-timeout,集群就会挂掉 解决方法把cluster-node-timeout调大

主从库数据不一致的问题 建议：
slave-serve-stale-data no 从库只能服务 INFO、SLAVEOF 命令,不能从从库读。

注意区分：slave-serve-stale-data 和 slave-read-only
slave-read-only 是设置从库能否处理写命令, slave-read-only 设置为 yes 时,从库只能处理读请求。
```

# 脑裂：一次奇怪的数据丢失

```java
脑裂: 指在主从集群中,同时有两个主节点,它们都能接收写请求。
    
脑裂最直接的影响,就是客户端不知道应该往哪个主节点写入数据,结果就是不同的客户端会往不同的主节点上写入数据。而且,严重的话,脑裂会进一步导致数据丢失。
 
    
为什么会数据丢失 ? 
1.可能是由于主库执行了命令,并通过命令传播给从服务器期间,主库崩溃了,进行主从切换,切换完毕数据丢失。
可以比对 原主库 master_repl_offset 和 原从库 slave_repl_offset 的差值,看是否是这个原因。
    
2.脑裂 
采用哨兵机制进行主从切换,如果原主库只是 "假故障" ,它会触发哨兵启动主从切换,一旦等它从假故障中恢复后,又开始处理请求,这样一来,就会和新主库同时存在,形成脑裂。
脑裂数据丢失的原因：等到哨兵让原主库执行(slave of)和新主库做全量同步后,原主库会清空本地的数据,加载新主库发送的 RDB 文件,原主库在主从切换期间保存的新写数据就丢失了。

 
解决脑裂问题 
min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量;
min-slaves-max-lag： 这个配置项设置了主从库间进行数据复制时,从库给主库发送 ACK 消息的最大延迟（以秒为单位）。
分别配置未 N 和 T 
 
主库连接的从库中至少有 N 个从库,和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒,否则,主库就不会再接收客户端的请求了。  假故障期间不能响应心跳也不能和从库进行同步,故也收不到ACK。就只能有新主库接受请求,等切换完成后,原主库会被哨兵降为从库,就不会出现脑裂进而出现数据丢失了。
   
脑裂发生的原因主要是原主库发生了假故障
   1.和主库部署在同一台服务器上的其他程序临时占用了大量资源(例如 CPU 资源)导致主库资源使用受限,短时间内无法响应心跳。
   2.主库自身遇到了阻塞的情况,处理 bigkey 或是发生内存 swap 短时间内无法响应心跳。
    
min-slaves-to-write 设置为 K/2+1 K为从库数量  min-slaves-max-lag 设置为十几秒
避免因为只有少数几个从库因为网络阻塞连不上主库,就禁止主库接收请求,增加了系统的鲁棒性<在异常和危险情况下系统生存的能力>。 
```

## 课后问题

```java
min-slaves-to-write 设置为 1, min-slaves-max-lag 设置为 15s, 哨兵的 down-after-milliseconds 设置为 10s,哨兵主从切换需要 5s。主库因为某些原因卡住了 12s,此时,还会发生脑裂吗?主从切换完成后,数据会丢失吗 ? 
    
    主库卡住 12s，达到了哨兵设定的切换阈值,所以哨兵会触发主从切换。但哨兵切换的时间是 5s,也就是说哨兵还未切换完成,主库就会从阻塞状态中恢复回来,而且也没有触发 min-slaves-max-lag 阈值,所以主库在哨兵切换剩下的 3s 内,依旧可以接收客户端的写操作,如果这些写操作还未同步到从库,哨兵就把从库提升为主库了,那么此时也会出现脑裂的情况,之后旧主库降级为从库,重新同步新主库的数据,新主库也会发生数据丢失。
```

#  Redis支撑秒杀场景的关键技术和实践都有哪些？

```java
秒杀场景的负载特征

第一个特征是瞬时并发访问量非常高 
当有大量并发请求涌入秒杀系统时,我们就需要使用 Redis 先拦截大部分请求,避免大量请求直接发送给数据库，把数据库压垮。
第二个特征是读多写少,而且读操作是简单的查询操作。
    
秒杀场景的各个阶段
第一阶段是秒杀活动前  把商品详情页的页面元素静态化  CDN 或是浏览器把这些静态化的元素缓存起来
    
第二阶段是秒杀活动开始 
1.库存查验(最大并发压力)  2.库存扣减    3.订单处理(保证处理的事务性,需要放在数据库中) 

库存扣减的操作不能放在数据库中 
1)最新数据在数据库,数据更新后需要与Redis同步,额外开销  
2)数据库处理较慢,大量请求读取到旧值,出现超售                    
3)库存查验和库存扣减这两个操作需要保证原子性
  

第三阶段 秒杀活动结束后 服务器端一般都能支撑
         
Redis 的哪些方法可以支撑秒杀场景 ？
1.支持高并发 (本身高速处理请求的特性) 使用集群避免请求发到一个实例  
2.保证库存查验和库存扣减原子性执行
2.1 LUA脚本保证原子性
2.2 使用分布式锁来保证多个客户端能互斥执行这两个操作 
    使用切片集群中的不同实例来分别保存分布式锁和商品库存信息,获取分布式锁才能执行库存查验和库存扣减。
    
Redis只是一个环节,还需要其他环节配合
1.CDN 
2.请求拦截和限流 
3.不要设库存信息过期时间,避免缓存击穿
4.订单处理出错重试,保证成功。
```

## 课后问题

```java
秒杀系统最重要的是,把大部分请求拦截在最前面,只让很少请求能够真正进入到后端系统,降低后端服务的压力。
    
    
假设一个商品的库存量是 800,我们使用一个包含了 4 个实例的切片集群来服务秒杀请求。我们让每个实例各自维护库存量 200,然后,客户端的秒杀请求可以分发到不同的实例上进行处理,你觉得这是一个好方法吗 ?
    

能否达到一个好的效果,主要取决于,客户端请求能不能均匀地分发到每个实例上。如果可以的话,那么,每个实例都可以帮着分担一部分压力,避免压垮单个实例。 需要在客户端和实例间就需要有代理层来完成请求的转发,否则客户端会根据 key 和 Slot 的映射关系,以及 Slot 和实例的分配关系,直接把请求发给保存 key 的唯一实例了。
```

# 数据分布优化：如何应对数据倾斜？

```java
数据倾斜
1.实例上的数据分布不均衡,某个实例上的数据特别多。
2.数据访问倾斜 实例的数据分布均衡,但是某个实例的数据是热点数据,导致访问频繁。
   
数据倾斜 数据在切片集群的多个实例上分布不均衡，大量数据集中到了一个或几个实例上
1.bigkey  bigkey 的 value 值很大(String 类型),或者是 bigkey 保存了大量集合元素 (集合类型)
  避免bigKey
    1)业务层生成数据时,要尽量避免把过多的数据保存在同一个键值对中
    2)把 bigkey 拆分成很多个小的集合类型数据,分散保存在不同的实例上
    
2.Slot 手工分配不均 使用CLUSTER SLOTS  查看 SLOT 的分配,如果某一个实例上有太多的Slot,使用迁移命令迁移到其他实例。
    
3.Hash Tag 导致倾斜  key为 k{xxxx} 只对xxxx计算CRC16的值  用于支持事务操作和范围查询。
因为Redis 不支持跨实例的事务操作和范围查询   使用 Hash Tag 将数据集中到某些实例上。
    
数据访问倾斜  
实例上存在热点数据 

对于<只读热点数据> 可以采取 热点数据多副本,把热点数据复制多份,在每一个数据副本的 key 中增加一个随机前缀,让他们被映射到不同的 Slot 中,并将Slot分配到不同的实例,这样不同的实例就都能提供访问。
```

## 课后问题

```java
在有数据访问倾斜时，如果热点数据突然过期了，而 Redis 中的数据是缓存，数据的最终值保存在后端数据库，此时会发生什么问题？

缓存击穿,热点请求会直接打到后端数据库上,数据库的压力剧增,可能会压垮数据库。
```

# 通信开销：限制Redis Cluster规模的关键因素

```java
Redis Cluster 最多 1000 个实例
例间的通信开销会影响集群的吞吐量  
    
    
Gossip 会传递自身的状态信息+集群十分之一实例的状态信息     
    
Gossip 协议的工作原理
1.每个实例之间会按照一定的频率,从集群中随机挑选一些实例,把 PING 消息发送给挑选出来的实例,用来检测这些实例是否在线,并交换彼此的状态信息。PING 消息中封装了发送消息的实例自身的状态信息、1/10 其它实例的状态信息,以及 Slot 映射表。
2. 一个实例在接收到 PING 消息后,会给发送 PING 消息的实例发送一个 PONG 消息。PONG 消息包含的内容和 PING 消息一样。
    
    
    
Gossip 协议进行通信时,通信开销受到通信消息大小和通信频率这两方面的影响   
    
Gossip 10KB  PING 12KB (加上Hash槽 16,384 bit)

1.通信消息大小不能改变 因为要维持集群状态的统一
 
周期性发送 PING     
Redis Cluster 的实例启动后,默认会每秒从本地的实例列表中随机选出 5 个实例,再从这 5 个实例中找出一个最久没有通信的实例,把 PING 消息发送给该实例。  

Redis Cluster 的实例会按照每 100ms 一次的频率，扫描本地的实例列表,如果发现有实例最近一次接收 PONG 消息的时间,已经大于配置项 cluster-node-timeout 的一半了 (cluster-node-timeout/2),就会立刻给该实例发送 PING 消息,更新这个实例上的集群状态信息。
    
每秒 PING 消息发送数量 =  1 + 10 *   实例数 (最近一次接收 PONG 消息的时间超出 cluster-node-timeout/2）   
    
    
2.降低实例间发送消息的频率  可以调整   
调整 cluster-node-timeout 时间 缓解由于PONG消息接收超时的情况,但也要避免设置过大。
如果 cluster-node-timeout 过大,发生故障,就需要等待更长时间才能检测出,从而导致了故障恢复时间被延长,影响集群服务的使用。
                                      
核心就是  合理设置集群数目,避免因为集群过大,集群之间通信开销大于 处理请求的开销,划不来。
```

**cluster-node-timeout  定义了集群实例被判断为故障的心跳超时时间**

## 课后问题

```java
如果我们采用跟 Codis 保存 Slot 分配信息相类似的方法,把集群实例状态信息和 Slot 分配信息保存在第三方的存储系统上 (例如 Zookeeper),这种方法会对集群规模产生什么影响吗 ? 
    
无论集群实例有多少，这些信息在第三方存储上只会存储一份，也就是说，集群内的通信开销，不会随着实例的增加而增长。当集群需要用到这些信息时，直接从第三方存储上获取即可。
```



# 常见面试题补充

```java
1. 什么是Redis

   Redis是 C 语言开发的内存数据库，由于是内存数据库，所以读写速度非常快，常用来做缓存，除了做缓存还可以实现分布式锁，和轻量级的消息队列，它提供了多种数据结构来应对不同的场景，还支持事务，持久化与集群

2. 分布式缓存常见的技术选型方案有哪些

   Memcached，Redis 

3. 说一下 Redis 和 Memcached 的区别和共同点

   相同

   + 都是基于内存的数据库，一般都用来当做缓存使用
   + Memcached 和 Redis 采用哈希表作为 key-value 索引 ，索引的作用是让键值数据库根据 key 找到相应 value 的存储位置
   + Memcached 和 Redis 都是通过网络框架实现客户端和服务端通信，网络框架中包括 Socket Server 和 协议解析
   + 都有过期策略  

   不同点

   + Memcached 支持的 value 类型仅为 String 类型，而 Redis 支持的 value 类型包括了 String、哈希表、列表、集合等
   + Memcached只支持将数据存储在内存中，Redis提供了持久化功能
   + Redis有原生集群模式  Cluster 
   + Memcached 是多线程，Redis 使用单线程的多路 IO 复用模型，Redis 6.0引入了多线程
   + Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除 
   + Redis支持事务  

4. 缓存数据的处理流程是怎样的 

   如果用户请求缓存命中就直接返回，发生缓存缺失则读取数据库 ，数据库中存在的话就更新缓存中的数据并返回，数据库中不存在的话就返回空数据 

5. 为什么要用Redis / 缓存 

   1. 高性能  使用缓存只需要第一次需要查询数据库，可以减少读磁盘的随机IO，当然要保证缓存一致性
   2. 高并发  直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，如果缓存能在缓存处理就可以避免发给数据库，避免数据库压力过大

6. Redis 除了做缓存，还可以做什么 

   1.分布式锁  分布式锁算法 Redlock；2.消息队列；3.复杂的业务场景比如统计一亿个key，排行榜，UV统计 ；

   4.限制用户访问次数——限流(Redis + LUA )

7. Redis 对象 

   字符串对象String 、 列表对象LIST、  哈希对象HASH、  集合对象SET、    有序集合Sort Set、                                 二值统计Bitmap、   基数统计HyperLogLog

8. Redis 单线程模型 

   Redis事件分为文件事件和时间事件，文件事件处理器是基于单Reactor单线程模式实现的，Redis处理请求和响应式通过文件事件实现的，所以Redis是单线程，它包含多个 socket（客户端连接），I/O多路复用程序，文件事件分派器，事件处理器(连接应答处理器、命令请求处理器、命令回复处理器)  

9. 为什么Redis 不使用多线程 

   Redis是单线程指的是Redis 的 网络 IO 和 键值对读写是由一个线程来完成的，持久化、异步删除、集群数据同步是由其他的线程完成的；而且Redis主线程是基 Linux 中的 IO 多路复用机制的高性能 I/O 模型，如果使用多个线程同时访问共享资源，为了保证正确性，就需要额外的机制来保证例如引入同步原语从而导致额外的开销

   1. 单线程编程容易并且更容易维护；
   2. Redis 的性能瓶颈不在 CPU ，主要在内存和网络；
   3. 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能

10. Redis 6.0 之后为何引入了多线程

    **Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。不会导致线程安全问题 

11. Redis 给缓存数据设置过期时间有啥用

    因为内存是有限的，如果缓存中的所有数据都是一直保存的话，导致内存溢出 Redis有两种过期删除策略，1. 惰性删除   2. 定期删除策略  3.定时删除   Redis采用的是定期删除策略+惰性删除

```

# Redis 6.0的新特性：多线程、客户端缓存与安全

```java
面向网络处理的多 IO 线程、客户端缓存、细粒度的权限控制，以及 RESP 3 协议
    
多个 IO 线程来处理网络请求,继续使用单线程执行命令操作  
```

